{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from langdetect import detect\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cld3\n",
    "import math\n",
    "from dataset import *\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset = train.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset.to_csv('data/train_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>reliable_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>belle sebastian</td>\n",
       "      <td>legal man</td>\n",
       "      <td>Pop</td>\n",
       "      <td>en</td>\n",
       "      <td>L-O-V-E love, it's coming back, it's coming ba...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pete townshend</td>\n",
       "      <td>a friend is a friend</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>When eyes meet in silence\\nA pact can be made\\...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blossoms</td>\n",
       "      <td>love talk</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>my eyes align with you\\nyou're on my side\\nand...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bukka white</td>\n",
       "      <td>parchman farm blues</td>\n",
       "      <td>Folk</td>\n",
       "      <td>en</td>\n",
       "      <td>Judge gimme me life this morn'in\\nDown on Parc...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pat benatar</td>\n",
       "      <td>i won't</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>I was there when you cried like a baby\\nWhen y...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Artist                  Song Genre Language  \\\n",
       "0  belle sebastian             legal man   Pop       en   \n",
       "1   pete townshend  a friend is a friend  Rock       en   \n",
       "2         blossoms             love talk  Rock       en   \n",
       "3      bukka white   parchman farm blues  Folk       en   \n",
       "4      pat benatar               i won't  Rock       en   \n",
       "\n",
       "                                              Lyrics reliable_lang  \n",
       "0  L-O-V-E love, it's coming back, it's coming ba...            en  \n",
       "1  When eyes meet in silence\\nA pact can be made\\...            en  \n",
       "2  my eyes align with you\\nyou're on my side\\nand...            en  \n",
       "3  Judge gimme me life this morn'in\\nDown on Parc...            en  \n",
       "4  I was there when you cried like a baby\\nWhen y...            en  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/csv/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"I met a girl on Christmas day\\nShe stole my heart took my breath away\\nWe were young and quite naive\\nYoung enough we still believed\\n\\nThat love never dies\\nIt just grows throughout our lifetime\\nAnd girl you know it's true\\nHere's a Christmas song for you, baby\\nHey girl\\nMerry Christmas girl, yeah\\n\\nAt this special time of year\\nI am thankful that you're still here\\nThere'll be mistletoes and color lights for the Christmas tree\\nThey barely define what you mean to me\\n\\nBaby love never dies\\nIt just grows throughout our lifetime\\nAnd girl you know it's true\\nHere's a Christmas song for you, baby\\nI love you girl, yeah\\n\\nIn my heart I always knew\\nThat I would spend my whole life with you\\nSo may your holidays be merry and be raised\\nAnd may your world be at peace tonight\\n\\nBaby love never dies\\nIt just grows throughout our lifetime\\nAnd girl you know it's true\\nYou're like a light in my life shining through\\nIf there was only one thing I could do\\nI'd sing this Christmas song to you\",\n",
       "       'I\\'m glad that you accepted\\nMy offer to you when I said\\n\"Excuse me Miss, what\\'s your name\"\\nThat was the spark that lit the flame\\n\\nYou won\\'t be regrettin\\' it\\nI promise you\\'ll be satisfied\\nSo relax, \\'cause everything\\'s gonna be all right\\n\\nGirl, I\\'m glad that I got you home tonight\\nFinally we are alone tonight\\nI\\'m gonna turn down the lights\\nI\\'ll give you what you like\\nGirl, I\\'m glad that I got you home\\nNow that I got you home tonight\\n\\nFirst let me take your coat off\\nAnd let me show you all around\\nAnd if you need somethin\\'\\nI think you ought to get it now\\n\\n\\'Cause we\\'ll be busy\\nDoin whatever\\'s cool\\nAnd I don\\'t want interruptions\\nBetween me and you\\n\\nGirl, I\\'m glad that I got you home tonight\\nFinally we are alone tonight\\nI\\'m gonna turn down the lights\\nI\\'ll give you what you like\\nGirl, I\\'m glad that I got you home\\nNow that I got you home tonight\\n\\nI can\\'t imagine bein\\' in another place\\nExcept with you, face to face\\nI can\\'t imagine bein\\' in another place\\nExcept with you, face to face\\n\\n\\'Cause I\\'ve been waitin\\'\\nSo long for this moment to come\\nAnd now you\\'re here in my arms\\n\\nGirl, I\\'m glad that I got you home tonight\\nFinally we are alone tonight\\nI\\'m gonna turn down the lights\\nI\\'ll give you what you like\\nGirl, I\\'m glad that I got you home\\nGlad that I got you home tonight\\n\\nI got you home tonight\\nI got you home tonight, girl\\nI got you home my baby\\nI got you home all right\\nI got you home my girl\\nI got you home now, baby\\nI got you home \\nI got you home tonight \\n\\nGirl, I\\'m glad that I got you home tonight\\nFinally we are alone tonight\\nI\\'m gonna turn down the lights\\nI\\'ll give you what you like\\nGirl, I\\'m glad that I got you home\\nGlad that I got you home tonight',\n",
       "       \"I was so busy doing things\\nDoing things that I wasn't supposed to\\nAnd I, know you might not believe me babe\\nBut I love you\\nFor each tear, forgive me\\nIt was honor that you loved me\\nThat I made you cry\\nI want you to know that I\\nI apologize, and I'm praying that it's not to late\\n\\n \\nGirl, if I, if I should lose you girl\\nIf I can't make love to you girl\\nIf I have thrown our love away\\nI don't know what I'm gonna do\\n\\nI can't imagine it\\nI can't imagine my life without you\\nAnd I, I can't even ? someone else loving you\\nDon't turn away from me\\nAnd leave me here, down on my knees\\nWithout you I'm dying\\nWon't you come save my life\\nNow I realize\\nThat I'll never love the way that I love you\\n\\n \\n\\nOhhhh, I know, I know I was wrong\\nWith you I belong\\nIf our love is gone\\nHow can I carry on\\nI'm so alone\\nWithout you to hold\\nWon't you come home If I\\n\\n \",\n",
       "       ...,\n",
       "       \"I hate wakin' up in the mornin'\\nWith twisted thoughts runnin' through my head\\nAll alone in love and lazy\\nCuz I'd rather be in your bed\\n\\nCuz you me lovin' so fine\\nSho nuff one of a kind\\nTakin' me to places unfound\\nYou give me lovin' so fine -- Sho doo\\n\\nAs dawn approaches baby I shiver\\nAnticipating the new day\\nCuz I'm sure to cry in rhythm\\nThinkin' of the many ways\\n...that you give me...\\n\\nChorus\\n\\nBridge\\n\\nI'm so addicted to your stuff\\n'M always in need of your sweet touch\\nSaid I'm a junkie for your love\\nS' tell me when, I'll have the chance again\\n\\nYou give give good lovin' so fine\\nSho nuff one of a kind\\nTakin' me to places unfound\",\n",
       "       \"Yea\\nGotta love this\\nNS\\nFor real\\nJust rock with it like\\nUh huh, uh huh, huh\\n\\nFo Shizzle\\n\\nG.A.N.G.S.T.A\\nFrom what I see girl its a must we stay\\nTogether Forever\\nYou see cause ever is ever\\nAnd never ever would nobody do it better\\nThan the S, oh yes\\nGuess your blessed\\nI put the rocks on your fingers,\\nEarrings jingle\\nNo more single\\nYou gotta man in your life\\nAnd I understand what your like\\nYour friends don't understand why you be seeing me\\nBut they don't understand your love is treating me\\nThe way I walk,\\nThe way I Look,\\nThe I talk,\\nThe way we make love in the dark\\nSomethings in life were meant to be\\nI thank God above that you were sent for me\\nSee cause my point of view is all about you\\nYou got to tell me what you want girl\\n\\nIt ain't a thing, mama, anything\\nYou need from me baby, please take this ring\\nIt's like braille\\nGirl the way I feel\\nIt's something that I can't conceal\\nFor sure you're my light\\nPersonified\\nMyself I can only try\\nTo measure your shine\\nOn an earthly scale\\nEverything else is pale\\nCompared to you\\n\\n \\nBaby you're my cure, you're my remedy\\nSo sincere and pure, said I'll never leave\\nI'll stay by your side, for eternity\\nTil the day I die babe\\nSaid you're my cure, you're my remedy\\nSo sincere and pure, said I'll never leave\\nI'll stay by your side, for eternity\\nTil the day I die because\\n\\n \\nBaby you're just right for me\\n(You're just right for me, babe)\\nI'm just right for you\\n(And I just wanna share your life)\\nCome and share your life with me\\n(Share your life with me babe)\\nAnd I'll share my life with you\\n(And I'll share my life with you, girl)\\n\\nAnything that I may have\\nAnything that I'm blessed to grab\\nI'll split it in half\\nFor your tender touch\\nYour loving girl it means so much\\nI'll love you in style\\nOn a sun drenched isle\\nAfter we go down the aisle\\nYou're the thrill in my life\\nOur love is amplified\\nThe type that only God provides\\nAnd it comes from you\\n\\n \\n\\n \\n\\nAnd if it's love you need\\nI'll give it to you baby\\nAnd if you want the world on a platter\\nI'll give it to you baby\\nSaid if it's up to me\\nI'll give it to you baby\\nAnything you need it don't matter\\nI'll give it to you baby\\n\\n \\n\\n \\n\\nBaby your just right for me\\n(your just right for me babe)\\nI'm just right for you\\n(yeah, baby come and share your life)\\nCome and share your life with me\\n(just share your life with me babe)\\nAnd ill share my life with you\\nBaby your just right for me\\nI'm just right for you\\nCome and share your life with me\\nAnd ill share my life with you\",\n",
       "       \"Well I think I'm going out of my head\\nYes I think I'm going out of my head over you, oh you\\nI want you to want me, I need you so badly\\nI can't think of anything but you yeah\\n\\nAnd I think I'm going out of my head\\n'Cause I can't explain these tears that I've shed\\nBaby over you, over you\\nI see you each morning\\nBut you just walk past me\\nYou don't even notice I exist\\n\\nGoing out of my head over you baby\\nOut of my head over you darlin'\\nBeen out of my head (baby) oh baby\\n(Day and night) Night and day and night, (oh) so right\\n\\nI must think of a way into your heart\\nThere's no reason why\\nMy being shy should keep us apart\\n\\nYeah ohh (hoobop shoobop baby)\\n(Shoobop Shoobop my love)\\nI see you each morning\\nBut you just walk past me\\nYou don't even notice that I exist\\n\\nGoing out of my head over you darlin'\\nOut of my head over you\\nOut of my head\\nI'm going going going going going\\nGirl girl yeah\\nI'm going going going going going\\nCom' on\\nGive me give me your loving\\nCom' on, com' on\\nGive me give me your loving\\nCom' on, com' on\\nGive me give me your loving\\nCom' on, com' on\\nGive me give me your loving\\nCom' on\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Genre'].apply(lambda x: x in ['R&B'])]['Lyrics'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "data = data[data['Language']=='en']\n",
    "data = data[data['Lyrics'].apply(lambda x: '\\n' in x)]\n",
    "data = data.drop_duplicates(subset=['Artist', 'Song', 'Genre'], ignore_index=True)\n",
    "data = data[data['Lyrics'].apply(lambda x: '---------' not in x)]\n",
    "data['Lyrics'] = data['Lyrics'].apply(lambda x: re.sub('\\[.*\\]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_en(line):\n",
    "    result = cld3.get_language(line)\n",
    "    lang = result[0]\n",
    "    reliable = result[2]\n",
    "    if reliable and lang == 'en':\n",
    "        return 'en'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192123"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reliable_lang'] = data['Lyrics'].apply(check_en)\n",
    "data = data[data['reliable_lang']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(data))\n",
    "train_index, test_index = train_test_split(indices, test_size = 0.1)\n",
    "train_index, dev_index = train_test_split(train_index, test_size=0.1)\n",
    "\n",
    "train_data = data.iloc[train_index].reset_index(drop=True)\n",
    "dev_data = data.iloc[dev_index].reset_index(drop=True)\n",
    "test_data = data.iloc[test_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('data/csv/train.csv', index=False)\n",
    "dev_data.to_csv('data/csv/dev.csv', index=False)\n",
    "test_data.to_csv('data/csv/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          96376\n",
       "Pop           70438\n",
       "Metal         15910\n",
       "Jazz          11701\n",
       "Folk           6922\n",
       "Indie          5592\n",
       "R&B            1572\n",
       "Electronic      447\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Genre']=='Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          8679\n",
       "Pop           6313\n",
       "Metal         1490\n",
       "Jazz          1035\n",
       "Folk           603\n",
       "Indie          497\n",
       "R&B            171\n",
       "Electronic      36\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz = data[data['Genre']=='Jazz'].reset_index(drop=True)\n",
    "indices = np.arange(len(jazz))\n",
    "train_index, test_index = train_test_split(indices, test_size = 0.1)\n",
    "train_index, dev_index = train_test_split(train_index, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/train/jazz_train.txt'\n",
    "with open(path,'w', encoding='utf-8', errors='ignore') as f:\n",
    "    for i in train_index:\n",
    "#         f.write(\"ARTIST NAME: \"+jazz['Artist'].iloc[i]+'\\n')\n",
    "#         f.write(\"GENRE: \"+jazz['Genre'].iloc[i]+'\\n')\n",
    "        f.write(jazz['Lyrics'].iloc[i])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in list(data['Genre'].value_counts().index):\n",
    "    df = data[data['Genre']==g]\n",
    "    artist = np.array(df['Artist']).reshape(-1,1)\n",
    "    genre = np.array(df['Genre']).reshape(-1,1)\n",
    "    lyrics = np.array(df['Lyrics']).reshape(-1,1)\n",
    "\n",
    "    out = np.hstack((artist, genre, lyrics))\n",
    "    file_path = 'data/'+g+'_train.npy'\n",
    "    np.save(file_path, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = np.array(rnb['Artist']).reshape(-1,1)\n",
    "genre = np.array(rnb['Genre']).reshape(-1,1)\n",
    "lyrics = np.array(rnb['Lyrics']).reshape(-1,1)\n",
    "\n",
    "rnb_out = np.hstack((artist, genre, lyrics))\n",
    "np.save('data/rnb_train.npy', rnb_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(rnb['Lyrics'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haowei/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rnb['detect_lang'] = rnb['Lyrics'].apply(lambda x: detect(x[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          103721\n",
       "Pop            83620\n",
       "Metal          17207\n",
       "Jazz           11760\n",
       "Folk            7023\n",
       "Indie           6033\n",
       "R&B             1575\n",
       "Electronic       462\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnb = create_ngram_model(NgramModel, 'data/csv/train.csv', 4,0.0000001,genre='R&B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnb6 = create_ngram_model(NgramModel, 'data/csv/train.csv', 6,0.0000001,genre='R&B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I will in my loaded came'"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnb.gen_next_sent('I like')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/csv/test.csv')\n",
    "train_df = pd.read_csv('data/csv/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,len(test_df)-1)\n",
    "lyric = test_df.iloc[idx]['Lyrics']\n",
    "# tot_pp += model.perplexity(lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully built dataset...\n",
      "index of new line character:  9754\n",
      "index of comma:  8035\n",
      "index of <UNK>:  10688\n"
     ]
    }
   ],
   "source": [
    "spec_dict = {\"dropout\": 0.5,\n",
    "                 \"num_lstm_layers\": 2,\n",
    "                 \"bilstm_flag\": True,\n",
    "                 \"word_bilstm_flag\": False,\n",
    "                 \"use_artist\": True,\n",
    "                 \"char_hidden_dim\": 128,\n",
    "                 \"char_emb_dim\": 50,\n",
    "                 \"char_model_type\": \"LSTM\",\n",
    "                 \"word_emb_dim\": 128,\n",
    "                 \"pre_train_word_embedding\": None,\n",
    "                 \"feature_emb_dim\": 128,\n",
    "                 \"final_hidden_dim\": 512,\n",
    "                 \"iterations\": 2000,\n",
    "                 \"print_every\": 100,\n",
    "                 \"plot_every\": 50}\n",
    "ds = Dataset('./data/csv/train.csv', subset=['R&B'])\n",
    "vocab_size = ds.tokenize_corpus(word_tokenize)\n",
    "print(\"Successfully built dataset...\")\n",
    "print(\"index of new line character: \", ds.word2idx['\\n'])\n",
    "print(\"index of comma: \", ds.word2idx[','])\n",
    "print(\"index of <UNK>: \", ds.word2idx['<UNK>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved_data/artist_set.p', \"wb\") as fp:\n",
    "    pickle.dump(ds.artist_set, fp)\n",
    "with open('saved_data/genre_set.p', 'wb') as fp:\n",
    "    pickle.dump(ds.genre_set, fp)\n",
    "with open('saved_data/word2idx.p', 'wb') as fp:\n",
    "    pickle.dump(ds.word2idx, fp)\n",
    "with open('saved_data/idx2word.p', 'wb') as fp:\n",
    "    pickle.dump(ds.idx2word, fp)\n",
    "with open('saved_data/phones2index.p', 'wb') as fp:\n",
    "    pickle.dump(ds.phones2index, fp)\n",
    "with open('saved_data/index2phones.p', 'wb') as fp:\n",
    "    pickle.dump(ds.index2phones, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = WordSequence(spec_dict, ds)\n",
    "model, loss_list = train(model, ds, spec_dict, num_lines=2)\n",
    "torch.save(model.state_dict(), 'model3.pt')\n",
    "plt.plot(loss_list)\n",
    "plt.show()\n",
    "pred_lines = predict(model, ds)\n",
    "print(pred_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target, artist, genre, next_line = ds.random_lyric_chunks(path = \"data/csv/train.csv\", subset=[\"R&B\"], num_lines=4, if_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp, target, artist, genre, next_line = ds.random_lyric_chunks(path = \"data/csv/train.csv\", subset=[\"R&B\"], num_lines=2, if_train=False)\n",
    "inp = \"Are you ready ? \"\n",
    "target = inp\n",
    "input_list = gen_input(ds, inp, target, artist, genre, if_train=False)\n",
    "res = batchify_sequence_labeling(input_list, False)\n",
    "(word_seq_tensor, feature_seq_tensors, word_seq_lengths, word_seq_recover, char_seq_tensor, char_seq_lengths,\n",
    "     char_seq_recover, ph_inputs, ph_seq_lengths, ph_seq_recover, target_seq_tensor, mask) = res\n",
    "batch_size = word_seq_tensor.size(0)\n",
    "seq_len = word_seq_tensor.size(1)\n",
    "genre_input = feature_seq_tensors[1]\n",
    "artist_input = feature_seq_tensors[0]\n",
    "outs = model(word_seq_tensor, genre_input, artist_input, word_seq_lengths, char_seq_tensor, char_seq_lengths, char_seq_recover,\n",
    "        ph_inputs, ph_seq_lengths, ph_seq_recover)\n",
    "outs = outs.view(batch_size * seq_len, -1)\n",
    "score = F.log_softmax(outs, 1)\n",
    "_, pred = torch.max(score, 1)\n",
    "pred = pred.view(batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10689])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = F.log_softmax(o1,1)\n",
    "_, pred = torch.max(score, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10578])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10578, 10578, 10578, 10578])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq_tensor.view(4)[-1].view(1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5748, 6473, 7967,  788]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7541, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(score, target_seq_tensor.view(4)[-1].view(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(788)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq_tensor.view(4)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'are you ready ? '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_lyrics(ds, target_seq_tensor.view(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.all_characters.index('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = torch.max(score, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3579, grad_fn=<UnbindBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.3579], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0][score[0] > -2.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10578, 10578, 10578, 10578])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scented unbeatable scented motivating '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_lyrics(ds, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n \\n \\n \\n '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_lyrics(ds, pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting next line..\n",
      "prediction input:  Our love is like water/angels \n",
      " Pinned down and abused \n",
      "\n",
      "prediction tensor:  tensor([[5064, 7653, 2464, 7563, 5617, 3331, 3863, 9343, 4211, 5617, 2971]])\n",
      "oh\n",
      "full word\n",
      "input len to lstm generation:  12\n",
      "prediction tensor:  tensor([[5064, 7653, 2464, 7563, 5617, 8930, 3863, 9343, 7563, 5617, 2971, 1330]])\n",
      "yeah\n",
      "full word\n",
      "input len to lstm generation:  13\n",
      "prediction tensor:  tensor([[5064, 7653, 2464, 7563, 5617, 8930, 3863, 9343, 7563, 5617, 2971, 1330,\n",
      "         9474]])\n",
      "me\n",
      "full word\n",
      "input len to lstm generation:  14\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643]])\n",
      ")\n",
      "full word\n",
      "input len to lstm generation:  15\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  16\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  17\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  18\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  19\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  20\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  21\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616,  9616,\n",
      "          9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  22\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616,  9616,\n",
      "          9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  23\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616,  9616,\n",
      "          9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  24\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616,  9616,\n",
      "          9616,  9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  25\n",
      "prediction tensor:  tensor([[ 5064,  7653,  2464,  7563,  5617,  8930,  3863,  9343,  7563,  5617,\n",
      "          2971, 10420,  9474,  7643,  9616,  9616,  9616,  9616,  9616,  9616,\n",
      "          9616,  9616,  9616,  9616,  9616]])\n",
      ".\n",
      "full word\n",
      "input len to lstm generation:  26\n",
      "('ohyeahme)...........', 'All over you  all over me')\n"
     ]
    }
   ],
   "source": [
    "pred_lines = predict(model, ds)\n",
    "print(pred_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(word_seq_tensor, feature_seq_tensors, word_seq_lengths, word_seq_recover, char_seq_tensor, char_seq_lengths, char_seq_recover, phone_seq_tensor, phone_seq_lengths, phone_seq_recover, target_seq_tensor, mask) = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build char sequence feature extractor: LSTM ...\n",
      "build char sequence feature extractor: LSTM ...\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "model = WordSequence(spec_dict, ds)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7676, 2313, 3358, 2017, 8924, 7537, 7537, 7676, 2313, 3358, 2017, 8924,\n",
       "         7537]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_seq_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-41eb1720d727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_seq_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_seq_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_seq_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_seq_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_seq_recover\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphone_seq_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphone_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphone_seq_recover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/lyrics-generation/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_inputs, genre_input, artist_input, word_seq_lengths, char_inputs, char_seq_lengths, char_seq_recover, ph_inputs, ph_seq_lengths, ph_seq_recover)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mword_represent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwordrep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martist_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_seq_recover\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mph_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph_seq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mph_seq_recover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0mpacked_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_represent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_seq_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/lyrics-generation/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_inputs, genre_input, artist_input, word_seq_lengths, char_inputs, char_seq_lengths, char_seq_recover, ph_inputs, ph_seq_lengths, ph_seq_recover)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_embs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mword_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenre_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_artist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mword_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model(word_seq_tensor, feature_seq_tensors[0], feature_seq_tensors[1], word_seq_lengths, char_seq_tensor, char_seq_lengths, char_seq_recover, phone_seq_tensor, phone_seq_lengths, phone_seq_recover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Said I'm sorry baby ,  said forgive me baby\\nNow you ain't never seen me on one\"\n",
    "tokens = re.split(\"[ ]+\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Said',\n",
       " \"I'm\",\n",
       " 'sorry',\n",
       " 'baby',\n",
       " ',',\n",
       " 'said',\n",
       " 'forgive',\n",
       " 'me',\n",
       " 'baby\\nNow',\n",
       " 'you',\n",
       " \"ain't\",\n",
       " 'never',\n",
       " 'seen',\n",
       " 'me',\n",
       " 'on',\n",
       " 'one']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
