{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from langdetect import detect\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cld3\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>world so cold</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>It starts with pain, followed by hate\\nFueled ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>broken</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>Freedom!\\nAlone again again alone\\nPatiently w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>3 leaf loser</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>Biting the hand that feeds you, lying to the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>anthem for the underdog</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>You say you know just who I am\\nBut you can't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 stones</td>\n",
       "      <td>adrenaline</td>\n",
       "      <td>Rock</td>\n",
       "      <td>en</td>\n",
       "      <td>My heart is beating faster can't control these...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Artist                     Song Genre Language  \\\n",
       "0  12 stones            world so cold  Rock       en   \n",
       "1  12 stones                   broken  Rock       en   \n",
       "2  12 stones             3 leaf loser  Rock       en   \n",
       "3  12 stones  anthem for the underdog  Rock       en   \n",
       "4  12 stones               adrenaline  Rock       en   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  It starts with pain, followed by hate\\nFueled ...  \n",
       "1  Freedom!\\nAlone again again alone\\nPatiently w...  \n",
       "2  Biting the hand that feeds you, lying to the v...  \n",
       "3  You say you know just who I am\\nBut you can't ...  \n",
       "4  My heart is beating faster can't control these...  "
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "data = data[data['Language']=='en']\n",
    "data = data[data['Lyrics'].apply(lambda x: '\\n' in x)]\n",
    "data = data.drop_duplicates(subset=['Artist', 'Song', 'Genre'], ignore_index=True)\n",
    "data = data[data['Lyrics'].apply(lambda x: '---------' not in x)]\n",
    "data['Lyrics'] = data['Lyrics'].apply(lambda x: re.sub('\\[.*\\]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_en(line):\n",
    "    result = cld3.get_language(line)\n",
    "    lang = result[0]\n",
    "    reliable = result[2]\n",
    "    if reliable and lang == 'en':\n",
    "        return 'en'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192123"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reliable_lang'] = data['Lyrics'].apply(check_en)\n",
    "data = data[data['reliable_lang']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(data))\n",
    "train_index, test_index = train_test_split(indices, test_size = 0.1)\n",
    "train_index, dev_index = train_test_split(train_index, test_size=0.1)\n",
    "\n",
    "train_data = data.iloc[train_index].reset_index(drop=True)\n",
    "dev_data = data.iloc[dev_index].reset_index(drop=True)\n",
    "test_data = data.iloc[test_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('data/csv/train.csv', index=False)\n",
    "dev_data.to_csv('data/csv/dev.csv', index=False)\n",
    "test_data.to_csv('data/csv/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          96376\n",
       "Pop           70438\n",
       "Metal         15910\n",
       "Jazz          11701\n",
       "Folk           6922\n",
       "Indie          5592\n",
       "R&B            1572\n",
       "Electronic      447\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Genre']=='Pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          8679\n",
       "Pop           6313\n",
       "Metal         1490\n",
       "Jazz          1035\n",
       "Folk           603\n",
       "Indie          497\n",
       "R&B            171\n",
       "Electronic      36\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz = data[data['Genre']=='Jazz'].reset_index(drop=True)\n",
    "indices = np.arange(len(jazz))\n",
    "train_index, test_index = train_test_split(indices, test_size = 0.1)\n",
    "train_index, dev_index = train_test_split(train_index, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/train/jazz_train.txt'\n",
    "with open(path,'w', encoding='utf-8', errors='ignore') as f:\n",
    "    for i in train_index:\n",
    "#         f.write(\"ARTIST NAME: \"+jazz['Artist'].iloc[i]+'\\n')\n",
    "#         f.write(\"GENRE: \"+jazz['Genre'].iloc[i]+'\\n')\n",
    "        f.write(jazz['Lyrics'].iloc[i])\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in list(data['Genre'].value_counts().index):\n",
    "    df = data[data['Genre']==g]\n",
    "    artist = np.array(df['Artist']).reshape(-1,1)\n",
    "    genre = np.array(df['Genre']).reshape(-1,1)\n",
    "    lyrics = np.array(df['Lyrics']).reshape(-1,1)\n",
    "\n",
    "    out = np.hstack((artist, genre, lyrics))\n",
    "    file_path = 'data/'+g+'_train.npy'\n",
    "    np.save(file_path, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = np.array(rnb['Artist']).reshape(-1,1)\n",
    "genre = np.array(rnb['Genre']).reshape(-1,1)\n",
    "lyrics = np.array(rnb['Lyrics']).reshape(-1,1)\n",
    "\n",
    "rnb_out = np.hstack((artist, genre, lyrics))\n",
    "np.save('data/rnb_train.npy', rnb_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(rnb['Lyrics'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haowei/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rnb['detect_lang'] = rnb['Lyrics'].apply(lambda x: detect(x[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock          103721\n",
       "Pop            83620\n",
       "Metal          17207\n",
       "Jazz           11760\n",
       "Folk            7023\n",
       "Indie           6033\n",
       "R&B             1575\n",
       "Electronic       462\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "\n",
      "so many people \n",
      "I know only a few \n",
      "yes I may say that I love this man \n",
      "and that man \n",
      "but what keeps me from loving you? \n",
      "date of birth  geography \n",
      "the color of my skin  ideology \n",
      "you got ten fingers  two legs  one nose \n",
      "like me \n",
      "just like me \n",
      "and it's as simple as that \n",
      "you see \n",
      "and if I don't know who to love \n",
      "I love them all \n",
      "and if I don't know who to trust \n",
      "I trust them all \n",
      "and if I don't know who to kill \n",
      "I may kill myself instead \n",
      "from the mouth of a baby \n",
      "will come the world-saving words \n",
      "that will save us all \n",
      "and from the lungs of a child \n",
      "will come the everlasting breath of god \n",
      "increasing peace and honesty \n",
      "and not carrying on despite of me \n",
      "don't you know \n",
      "this ain't about no race, no creed \n",
      "no race, no creed \n",
      "and it's as simple as that \n",
      "you see \n",
      "and if I don't know who to love \n",
      "I love them all \n",
      "and if I don't know who to trust \n",
      "I trust them all \n",
      "and if I don't know who to kill \n",
      "no suicide \n",
      "I'm already dead \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rnb.iloc[20]['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_model(model_class, path, n=2, k=0, type='csv', genre=None):\n",
    "    ''' Creates and returns a new n-gram model trained on path file '''\n",
    "    \"\"\"\n",
    "    path: numpy file of dimension nx3, columns: artist, genre, lyrics\n",
    "    \n",
    "    return: updated model of model_class\n",
    "    \"\"\"\n",
    "    num_iterations = 100  # number of samples to draw\n",
    "    length = 20  # how many lines in one sample\n",
    "\n",
    "    model = model_class(n, k)\n",
    "    if type == 'txt':\n",
    "        with open(path, encoding='utf-8', errors='ignore') as f:\n",
    "            lyrics = f.read()\n",
    "    else:\n",
    "        lyrics = csv_to_text(path, genre)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        temp = lyrics_chunks(lyrics, length)\n",
    "        model.update(temp)\n",
    "\n",
    "    return model\n",
    "\n",
    "def start_pad(n):\n",
    "    ''' Returns a padding string of length n to append to the front of text\n",
    "        as a pre-processing step to building n-grams '''\n",
    "    return '~' * n\n",
    "\n",
    "def ngrams(n, text):\n",
    "    ''' Returns the ngrams of the text as tuples where the first element is\n",
    "        the length-n context and the second is the character '''\n",
    "    adjusted_txt = start_pad(n) + text\n",
    "    gramlist = []\n",
    "    for i in range(n, len(adjusted_txt)):\n",
    "        ngram = (adjusted_txt[i-n:i], adjusted_txt[i])\n",
    "        gramlist.append(ngram)\n",
    "    return gramlist\n",
    "\n",
    "def csv_to_text(path, genre=None):\n",
    "    ''' Takes in a csv file and return the lyrics concatenated into one text file'''\n",
    "    df = pd.read_csv(path)\n",
    "    if genre:\n",
    "        df = df[df['Genre']==genre]\n",
    "    lyrics = '\\n'.join(list(df['Lyrics']))\n",
    "    return lyrics\n",
    "\n",
    "def lyrics_chunks(lyrics, length):\n",
    "    \"\"\"\n",
    "    randomly samples lyrics chunks of specified length\n",
    "\n",
    "    :param lyrics: str, entire lyrics corpus\n",
    "    :param length: int, number of lines in one lyrics chunks\n",
    "    :return: str, lyric lines joined by new line\n",
    "    \"\"\"\n",
    "    lyrics_lines = lyrics.split('\\n')\n",
    "    start_idx = random.randint(0, len(lyrics_lines)-1)\n",
    "    end_idx = min(start_idx+length, len(lyrics_lines))\n",
    "    selected_lyrics = lyrics_lines[start_idx:end_idx]\n",
    "    return '\\n'.join(selected_lyrics)\n",
    "\n",
    "################################################################################\n",
    "# Model\n",
    "################################################################################\n",
    "\n",
    "class NgramModel(object):\n",
    "    ''' A basic n-gram model using add-k smoothing '''\n",
    "\n",
    "    def __init__(self, n, k):\n",
    "        self.n = n\n",
    "        self.k = k\n",
    "        self.vocabs = []\n",
    "        self.context_list = {}\n",
    "        self.context_count = {}\n",
    "\n",
    "    def get_vocab(self):\n",
    "        ''' Returns the set of characters in the vocab '''\n",
    "        return set(''.join(self.vocabs))\n",
    "\n",
    "    def update(self, text):\n",
    "        ''' Updates the model n-grams based on text '''\n",
    "        self.vocabs.append(text)\n",
    "        # self.sorted_vocabs = list(set(self.vocabs))\n",
    "        # self.sorted_vocabs.sort()\n",
    "        gramlist = ngrams(self.n, text)\n",
    "        for pair in gramlist:\n",
    "            context = pair[0]\n",
    "            char = pair[1]\n",
    "            if context in self.context_list: # context previously showed up\n",
    "                self.context_count[context]+=1\n",
    "                if char in self.context_list[context]: # combination previously showed up\n",
    "                    self.context_list[context][char]+=1\n",
    "                else:\n",
    "                    self.context_list[context][char]=1\n",
    "            else:\n",
    "                self.context_count[context]=1\n",
    "                self.context_list[context] = {char: 1}\n",
    "\n",
    "    def prob(self, context, char, lambdas=None):\n",
    "        ''' Returns the probability of char appearing after context '''\n",
    "        if context not in self.context_list:\n",
    "            return 1/len(self.get_vocab())\n",
    "\n",
    "        # if char not in self.context_list[context]:\n",
    "        #     return 0.0\n",
    "        # else:\n",
    "        #     return self.context_list[context][char]/self.context_count[context]\n",
    "        count = 0\n",
    "        if char in self.context_list[context]:\n",
    "            count = self.context_list[context][char]\n",
    "        p = (count+self.k)/(self.context_count[context]+self.k*len(self.get_vocab()))\n",
    "        return p\n",
    "\n",
    "    def random_char(self, context):\n",
    "        ''' Returns a random character based on the given context and the\n",
    "            n-grams learned by this model '''\n",
    "        vocabs = list(self.get_vocab())\n",
    "        vocabs.sort()\n",
    "        total_prob = 0\n",
    "        r = random.random()\n",
    "        for i in range(len(vocabs)):\n",
    "            total_prob += self.prob(context, vocabs[i])\n",
    "            if total_prob > r:\n",
    "                return vocabs[i]\n",
    "        return vocabs[-1]\n",
    "\n",
    "    def random_text(self, length, context=None):\n",
    "        ''' Returns text of the specified character length based on the\n",
    "            n-grams learned by this model '''\n",
    "        if context == None:\n",
    "            context = start_pad(self.n)\n",
    "        else:\n",
    "            context = context[-self.n:]\n",
    "        text = ''\n",
    "        for i in range(length):\n",
    "            char = self.random_char(context)\n",
    "            text += char\n",
    "            context = context[1:]+char\n",
    "        return text\n",
    "\n",
    "    def random_lines(self, num_lines, context=None):\n",
    "        ''' Returns specified number of lines based on learned n-grams model'''\n",
    "        if context == None:\n",
    "            context = start_pad(self.n)\n",
    "        else:\n",
    "            context = context[-self.n:]\n",
    "        text = ''\n",
    "        count = 0\n",
    "        while True:\n",
    "            char = self.random_char(context)\n",
    "            if char == '\\n':\n",
    "                count += 1\n",
    "                if count == num_lines:\n",
    "                    break\n",
    "            text += char\n",
    "            context = context[1:] + char\n",
    "        return text\n",
    "    \n",
    "    def perplexity(self, text,lambdas=None):\n",
    "        ''' Returns the perplexity of text based on the n-grams learned by\n",
    "            this model '''\n",
    "        padded_text = start_pad(self.n) + text\n",
    "        context = start_pad(self.n)\n",
    "        log_pp = 0\n",
    "        for i in range(self.n, len(padded_text)):\n",
    "            p = self.prob(context, padded_text[i])\n",
    "            if p == 0:\n",
    "                return float('inf')\n",
    "            log_pp += math.log(p)\n",
    "            context = context[1:]+padded_text[i]\n",
    "        log_pp = log_pp/(-len(text))\n",
    "        pp = math.exp(log_pp)\n",
    "        return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = create_ngram_model(NgramModel, 'data/csv/train.csv', 5,0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that's all it takes me higher,\n",
      "My woman keeps me warm.\n",
      " \n",
      "What can, not live yet never though my style two thumbs up like using analogues haha\n",
      "I wreck shit for you\n",
      "Our reason to five pieces\n",
      "like the car, like fuck the very next day \n",
      "Then I hold you burn so easily\n",
      "What I'd give to me\n",
      "Is it d-d-destiny, d-destiny, d-destiny, d-destiny, d-destiny, d-destiny, d-destiny, d-destiny\n"
     ]
    }
   ],
   "source": [
    "print(m.random_lines(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_perplexity(model, test_df, model_type='ngram'):\n",
    "    \"\"\"\n",
    "    computes perplexity of unseen text using given model\n",
    "\n",
    "    :param model: learned model\n",
    "    :param test_df:\n",
    "    :param model_type: 'ngram' or 'neural', default is 'ngram'\n",
    "    :return: average perplexity score from 20 songs\n",
    "    \"\"\"\n",
    "    tot_pp = 0\n",
    "    num_samp = 500\n",
    "\n",
    "    if model_type == 'ngram':\n",
    "        # select 20 random songs from test data and compute perplexity\n",
    "        for i in range(num_samp):\n",
    "            idx = random.randint(0,len(test_df)-1)\n",
    "            lyric = test_df.iloc[idx]['Lyrics']\n",
    "            tot_pp += model.perplexity(lyric)\n",
    "\n",
    "#     if model_type == 'neural':\n",
    "#         for i in range(num_samp):\n",
    "#             idx = random.randint(len(test_df))\n",
    "#             lyric = test_df.iloc[idx]['Lyrics']\n",
    "#             tot_pp += nn_perplexity(lyric, model)\n",
    "\n",
    "    return tot_pp / num_samp\n",
    "\n",
    "# def nn_perplexity(val_text, model):\n",
    "#     input = char_tensor(val_text[:-1])\n",
    "#     target = char_tensor(val_text[1:])\n",
    "#     hidden = model.init_hidden()\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     loss = 0\n",
    "#     for i in range(len(val_text)-1):\n",
    "#         output, hidden = model(input[i], hidden)\n",
    "#         loss += criterion(output, target[i].view(-1))\n",
    "#     avg_loss = loss.item()/(len(val_text)-1)\n",
    "#     return np.exp(avg_loss)\n",
    "\n",
    "# def char_tensor(string):\n",
    "#     tensor = torch.zeros(len(string)).long()\n",
    "#     for c in range(len(string)):\n",
    "#         tensor[c] = all_characters.index(string[c])\n",
    "#     return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/csv/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0,len(test_df)-1)\n",
    "lyric = test_df.iloc[idx]['Lyrics']\n",
    "# tot_pp += model.perplexity(lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the middle of the night,\\nNo one heard the boy\\nWho cried himself to sleep\\nDidn't care about himself 'cause he\\nHurt too much, he was hurt too much\\nAnd the burden of the world was put\\nOn a hurting child, hurting child\\nWho never smiled\\nThe world was put on the hurting child,\\nHurting child\\nI sing for the hurting child\\nI sing for the hurting child\\n\\nIn the middle of the fight\\nNo one saw the girl who thought it\\nWas her fault, didn't know about her pain\\nThough it was right there\\nNo one said they cared\\nAnd the burden of the world was put\\nOn a hurting child, hurting child\\nWho never smiled\\nThe world was put on the hurting child,\\nHurting child\\nI sing for the hurting child\\n\\nI sing for the children, dream for the children,\\nCry for the children now\\nSo I sing for the children, dream for the children,\\nSmile for the children now\\nSaid the world was put\\nOn a hurting child, hurting child\\nWho never smiled\\nThe world was put on the hurting child,\\nHurting child\\nI sing for the hurting child\\n\\nI sing for the children, dream for the children,\\nCry for the children now\\nSo I sing for the children, dream for the children,\\nSmile for the children\\n...I was that hurting child\\n\""
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.90236795465054"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_perplexity(m, test_df,'ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NgramModel(5,0)\n",
    "for i in range(5000):\n",
    "    model.update(lyrics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "The blue night has come\n",
      "The moon is sending good vibes to everyone\n",
      "And we all gather around\n",
      "And head out to our own special place for fun\n",
      "'Cause here now it seem\n",
      "It's like a little beach reggae party\n",
      "Far away from city lights\n",
      "But blessed by the bloom of the starry nights\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Sexta blue, sexta blue\n",
      "Sexta blue, sexta blue\n",
      "Stomp the ground, yeah\n",
      "In the trance with the reggae sound\n",
      "Bodies jump up and down\n",
      "Up and down, yeah\n",
      "Emotion explodes around\n",
      "Bringing the unity most profound\n",
      "And revives contaminants\n",
      "Surrounding compound\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Sexta blue, sexta blue\n",
      "Sexta blue, sexta blue\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Blue Friday come stripping me away\n",
      "Put me in your arms\n",
      "When you play that good reggae\n",
      "I swear not to roam\n",
      "I'll always come home\n",
      "To where I can feel this and know\n",
      "Sexta blue, sexta blue\n",
      "Sexta blue, sexta blue\n",
      "Sexta blue, sexta blue\n",
      "Sexta blue, sexta blue\n",
      "[Mika Means:]\n",
      "Attention all club goers and party seekers,\n",
      "Oooh yeah, it's Mika Means,\n",
      "In the ATL everybody floss,\n",
      "Everytime I go out everything costs,\n",
      "Only money talks on Monday to Sunday\n",
      "Never only one day,\n",
      "Then party like a payday,\n",
      "Excuse me while I make my way to the front line of the club\n",
      "I just jumped out the truck,\n",
      "In the velvet room you can find me on stage\n",
      "With a cd in my hand talking to the DJ,\n",
      "If I ever lose my cool, gotta take it up top,\n",
      "Where it's cold and it's gritty,\n",
      "What's up New York city,\n",
      "Where they don't give a fuck\n",
      "Bout your story or your luck\n",
      "Everybody gotta hustle when you living up north,\n",
      "[Chorus:]\n",
      "I make big money, I drive big cars,\n",
      "Everybody know me,\n",
      "Everybody know me\n",
      "Everybody know me,\n",
      "Everybody know me,\n",
      "Everybody know me,\n",
      "I love big things,\n",
      "I like big bling\n",
      "Everybody know me,\n",
      "Everybody know me,\n",
      "When I wanna get away I MIA,\n",
      "Club Sobe they know me,\n",
      "Transport me to long beach,\n",
      "Hey bay bay,\n",
      "If I really want a party, hello LA,\n",
      "Hey dro all day, hey paparazzay,\n",
      "In the middle of the westside,\n",
      "I throw it this way,\n",
      "When I really wanna party, it's St Tropez,\n",
      "If you thinking what I'm thinking everybody say Ayy,\n",
      "Everybody say Ohh,\n",
      "Everybody bring the party from the VIP to the floor,\n",
      "Spend a little more,\n",
      "If you ain't making it then fake it then\n",
      "No matter what the cost is,\n",
      "Show em who the boss is,\n",
      "Say...\n",
      "[Chorus]\n",
      "[Lil Wayne:]\n",
      "Uh ummm, everybody know me,\n",
      "I stop..\n",
      "and let the bullshit go before me,\n",
      "And since I really ball, they be trying to throw me,\n",
      "King size bed, bad bitch below me,\n",
      "Walked up on her like what it do shorty,\n",
      "She replied shit whatever you can do for me,\n",
      "I told her I'm me, she said me to,\n",
      "I told her I'm a three and I make big money,\n",
      "I made young money,\n",
      "I got a lot of bitches you can take one from me,\n",
      "Weezy F and the F is for feature,\n",
      "Mean like Mika, huh\n",
      "[Chorus]\n",
      "[Intro:]\n",
      "We been together\n",
      "Over and over again\n",
      "And the feeling's the same\n",
      "Can't stay too far\n",
      "Too far apart\n",
      "Even if it's just a mile away\n",
      "[Chorus:]\n",
      "It's a two minute warning\n",
      "And I know that you want it\n",
      "It's a two minute warning\n",
      "And I know that you're horny\n",
      "It's a two minute warning\n",
      "And I know that you want it\n",
      "It's a two minute warning\n",
      "And I know that you're horny\n",
      "It's a two minute warning\n",
      "[Verse 1 - Big Sean:]\n",
      "You gonna make me quit what I'm doing\n",
      "And fall through with this bottle\n",
      "That ain't the only thing you finna swallow\n",
      "That ain't the only thing I got poppin\n",
      "That ain't the only thing that's finna spill quick\n",
      "No rubber shit I'm a still hit you\n",
      "My main bitch and that's real real real shit\n",
      "I'm a treat her like we on vacay, South Beach shit\n",
      "Only thing you wearing is sheets sets\n",
      "Talking to you like a little freak bitch\n",
      "Guess that's our little secret\n",
      "When I come through off in my zone\n",
      "Not that fuckin friend zone\n",
      "Only thing I touch is that end zone\n",
      "Look I don't care if it's ten phones\n",
      "They off\n",
      "Straight up\n",
      "You got your legs going way up\n",
      "When you hop on top and turn around\n",
      "I can't handle it\n",
      "I might pass out like a pamphlet\n",
      "You got a candle lit Cinnamon apple the candle scent\n",
      "Bed banging like a band in it\n",
      "You know I\n"
     ]
    }
   ],
   "source": [
    "print(lyrics[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['~~~~~'])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.context_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aIxPtb[KYIaP\n",
      "F.dAFzEkN[FSTVDlnnoE,IfqlshVHmz]Js-pbPCWDPxcK-SYyIWL1JqUyrEyd\n",
      "H1DOWS1c'mf:s\n",
      "x'jygrbvrez\n"
     ]
    }
   ],
   "source": [
    "print(model.random_text(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
